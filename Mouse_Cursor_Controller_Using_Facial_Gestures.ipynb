{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "B2V-UERNLvYI",
    "outputId": "7ee0cd3f-fcf0-43c1-9276-8c109bd6e769"
   },
   "outputs": [],
   "source": [
    "from imutils import face_utils\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import pyautogui as pag\n",
    "import imutils\n",
    "import cv2\n",
    "import dlib\n",
    "import speech_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wE8GNCxnLvy3"
   },
   "outputs": [],
   "source": [
    "# Thresholds and consecutive frame length for triggering the mouse action.\n",
    "MOUTH_AR_THRESH = 0.6\n",
    "MOUTH_AR_CONSECUTIVE_FRAMES = 10\n",
    "EYE_AR_THRESH = 0.19\n",
    "EYE_AR_CONSECUTIVE_FRAMES = 10\n",
    "WINK_AR_DIFF_THRESH = 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E6L0HiGkLv34"
   },
   "outputs": [],
   "source": [
    "# Initialize the frame counters for each action as well as \n",
    "# booleans used to indicate if action is performed or not\n",
    "MOUTH_COUNTER = 0\n",
    "EYE_COUNTER = 0\n",
    "WINK_COUNTER = 0\n",
    "INPUT_MODE = False\n",
    "EYE_CLICK = False\n",
    "LEFT_WINK = False\n",
    "RIGHT_WINK = False\n",
    "SCROLL_MODE = False\n",
    "ANCHOR_POINT = (0, 0)\n",
    "WHITE_COLOR = (255, 255, 255)\n",
    "YELLOW_COLOR = (0, 255, 255)\n",
    "RED_COLOR = (0, 0, 255)\n",
    "GREEN_COLOR = (0, 255, 0)\n",
    "BLUE_COLOR = (255, 0, 0)\n",
    "BLACK_COLOR = (0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gdw-yYAULv6a"
   },
   "outputs": [],
   "source": [
    "# Initialize Dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor\n",
    "shape_predictor = \"shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(shape_predictor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fDoDueGcLv9I"
   },
   "outputs": [],
   "source": [
    "# Grab the indexes of the facial landmarks for the left and\n",
    "# right eye, nose and mouth respectively\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "(nStart, nEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"nose\"]\n",
    "(mStart, mEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sBPp0qFJMBVV"
   },
   "outputs": [],
   "source": [
    "# Video capture\n",
    "vid = cv2.VideoCapture(0)\n",
    "resolution_w = 1366\n",
    "resolution_h = 768\n",
    "cam_w = 640\n",
    "cam_h = 480\n",
    "unit_w = resolution_w / cam_w\n",
    "unit_h = resolution_h / cam_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RkID12ooHo9N"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Grab the frame from the threaded video file stream, resize\n",
    "    # it, and convert it to grayscale\n",
    "    # channels)\n",
    "    ret, frame = vid.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame = imutils.resize(frame, width=cam_w+100, height=cam_h+100)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale frame\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "    # Loop over the face detections\n",
    "    if len(rects) > 0:\n",
    "        rect = rects[0]\n",
    "    else:\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        continue\n",
    "\n",
    "    # Determine the facial landmarks for the face region, then\n",
    "    # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "    # array\n",
    "    shape = predictor(gray, rect)\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "    # Extract the left and right eye coordinates, then use the\n",
    "    # coordinates to compute the eye aspect ratio for both eyes\n",
    "    mouth = shape[mStart:mEnd]\n",
    "    leftEye = shape[lStart:lEnd]\n",
    "    rightEye = shape[rStart:rEnd]\n",
    "    nose = shape[nStart:nEnd]\n",
    "\n",
    "    # Because I flipped the frame, left is right, right is left.\n",
    "    temp = leftEye\n",
    "    leftEye = rightEye\n",
    "    rightEye = temp\n",
    "\n",
    "    # Average the aspect ratio together for both eyes\n",
    "    mar = mouth_aspect_ratio(mouth)\n",
    "    leftEAR = eye_aspect_ratio(leftEye)\n",
    "    rightEAR = eye_aspect_ratio(rightEye)\n",
    "    ear = (leftEAR + rightEAR) / 2.0\n",
    "    diff_ear = np.abs(leftEAR - rightEAR)\n",
    "\n",
    "    nose_point = (nose[3, 0], nose[3, 1])\n",
    "\n",
    "    # Compute the convex hull for the left and right eye, then\n",
    "    # visualize each of the eyes\n",
    "    mouthHull = cv2.convexHull(mouth)\n",
    "    leftEyeHull = cv2.convexHull(leftEye)\n",
    "    rightEyeHull = cv2.convexHull(rightEye)\n",
    "    cv2.drawContours(frame, [mouthHull], -1, YELLOW_COLOR, 1)\n",
    "    cv2.drawContours(frame, [leftEyeHull], -1, YELLOW_COLOR, 1)\n",
    "    cv2.drawContours(frame, [rightEyeHull], -1, YELLOW_COLOR, 1)\n",
    "\n",
    "    for (x, y) in np.concatenate((mouth, leftEye, rightEye), axis=0):\n",
    "        cv2.circle(frame, (x, y), 2, GREEN_COLOR, -1)\n",
    "    \n",
    "    if mar > MOUTH_AR_THRESH:\n",
    "        MOUTH_COUNTER += 1\n",
    "\n",
    "        if MOUTH_COUNTER >= MOUTH_AR_CONSECUTIVE_FRAMES:\n",
    "            # if the alarm is not on, turn it on\n",
    "            INPUT_MODE = not INPUT_MODE\n",
    "            # SCROLL_MODE = not SCROLL_MODE\n",
    "            MOUTH_COUNTER = 0\n",
    "            ANCHOR_POINT = nose_point\n",
    "    else:\n",
    "        MOUTH_COUNTER = 0\n",
    "        \n",
    "    if diff_ear < WINK_AR_DIFF_THRESH:#eye is closed and less than wink thresh\n",
    "        if ear <= EYE_AR_THRESH:\n",
    "            EYE_COUNTER += 1\n",
    "            if EYE_COUNTER > EYE_AR_CONSECUTIVE_FRAMES:\n",
    "                cv2.putText(frame, 'SPEECH Recognition started!', (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, RED_COLOR, 2)\n",
    "                #code for speech recognition\n",
    "                recognizer = speech_recognition.Recognizer()\n",
    "                with speech_recognition.Microphone() as src:\n",
    "                    try:\n",
    "                        audio = recognizer.adjust_for_ambient_noise(src)\n",
    "                        audio = recognizer.listen(src,timeout=3)\n",
    "                        speech_to_txt = recognizer.recognize_google(audio).lower()\n",
    "                        if (speech_to_txt == \"double click\"):\n",
    "                            pag.doubleClick()\n",
    "                            EYE_COUNTER = 0\n",
    "                        elif(speech_to_txt == \"left click\"):\n",
    "                            pag.leftClick()\n",
    "                            EYE_COUNTER = 0\n",
    "                        elif(speech_to_txt == \"right click\"):\n",
    "                            pag.rightClick()\n",
    "                            EYE_COUNTER = 0                       \n",
    "                        elif(speech_to_txt == \"move\"):\n",
    "                            SCROLL_MODE = not SCROLL_MODE\n",
    "                            # INPUT_MODE = not INPUT_MODE\n",
    "                            EYE_COUNTER = 0\n",
    "                            # nose point to draw a bounding box around it\n",
    "                    except Exception as ex:\n",
    "                        EYE_COUNTER = 0\n",
    "        else:\n",
    "            EYE_COUNTER = 0\n",
    "    if INPUT_MODE:\n",
    "        cv2.putText(frame, \"READING INPUT!\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, RED_COLOR, 2)\n",
    "        x, y = ANCHOR_POINT\n",
    "        nx, ny = nose_point\n",
    "        w, h = 60, 35\n",
    "        multiple = 1\n",
    "        cv2.rectangle(frame, (x - w, y - h), (x + w, y + h), GREEN_COLOR, 2)\n",
    "        cv2.line(frame, ANCHOR_POINT, nose_point, BLUE_COLOR, 2)\n",
    "\n",
    "        dir = direction(nose_point, ANCHOR_POINT, w, h)\n",
    "        cv2.putText(frame, dir.upper(), (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, RED_COLOR, 2)\n",
    "        drag = 18\n",
    "        if dir == 'right':\n",
    "            pag.moveRel(drag, 0)\n",
    "        elif dir == 'left':\n",
    "            pag.moveRel(-drag, 0)\n",
    "        elif dir == 'up':\n",
    "            if SCROLL_MODE:\n",
    "                pag.scroll(40)\n",
    "            else:\n",
    "                pag.moveRel(0, -drag)\n",
    "        elif dir == 'down':\n",
    "            if SCROLL_MODE:\n",
    "                pag.scroll(-40)\n",
    "            else:\n",
    "                pag.moveRel(0, drag)\n",
    "\n",
    "    if SCROLL_MODE:\n",
    "        cv2.putText(frame, 'SCROLL MODE IS ON!', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, RED_COLOR, 2)\n",
    "\n",
    "    # cv2.putText(frame, \"MAR: {:.2f}\".format(mar), (500, 30),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, YELLOW_COLOR, 2)\n",
    "    # cv2.putText(frame, \"Right EAR: {:.2f}\".format(rightEAR), (460, 80),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, YELLOW_COLOR, 2)\n",
    "    # cv2.putText(frame, \"Left EAR: {:.2f}\".format(leftEAR), (460, 130),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, YELLOW_COLOR, 2)\n",
    "    # cv2.putText(frame, \"Diff EAR: {:.2f}\".format(np.abs(leftEAR - rightEAR)), (460, 80),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # If the `Esc` key was pressed, break from the loop\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "# Do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vid.release()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "project_si",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
